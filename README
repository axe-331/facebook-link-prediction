my implementation of supervised random walks algorithm in octave, as described in the paper Supervised Random Walks by Lars Backstorm.. The data I used is from the first facebook kaggle competition..

will update commets and notes soon.. and clear instructions of how to use this code..

traindata: http://sdrv.ms/TyUi3B
testdata: http://sdrv.ms/TuEu1Q


upervised Random Walks paper summary:

We are given snapshot of a network and would like to infer which interactions are likely to occur in near future or which existing interactions are missing.
The challenge is how to effectively combine imformation from the network structure with rich node and edge attribute data.

We achieve this by using the attributes to guide a random walk on the graph. We formulate a supervised learning task where the goal is to learn a function that assigns strengths to edges in the network such that a random walker is more likely to visit the nodes to which new links will be created.

Challenges:
	Networks are extremely sparse.
	How do we incorporate various features of the nodes and edges. how do network and node features interact in the creation of new links.

From technical point of view it is not clear how to develop a metho that, in a principled way, combines the features of nodes and edges. A common unsatisfactoy way is to simply extract a set of features describing the network structure around the two nodes of interest and combine it with user profile information.

Present work: Supervised Random Walks
We develop a concept of supervised random walks that naturally and in a principled way combine network features into a unified link predicting algorithm.

In a supervised way we learn how the bias page rank like random walk on the network, so that it visits given nodes more often than the others.

from node and edge features we obtain edge strengths(random walk transition probabilities) uch that random walk on a weighted network is more likely to visit positive than negative nodes.  positive are nodes which new edges will be created in the future, and negative are all other nodes.

we formulate a supervised learning task where we are given a source node s and a training examples about which nodes s will create new links to in future. The goal is to learn a function that a strength to each edge so that when computing the random walk scores in such a weighted network nodes to which s creates new links have higher scores to s than nodes to which s does not create links.

technically we should be able to show that such edge strength function can be learned directly and efficiently. We do not postulate what it means for edge to be strong in an adhoc way and then use this heuristic estimate. We show how to directly find the parameters of edge strength function which give optimal performance. This means we are able to compute gradient of the parameters of the edge strength fuction with respect to the page rank like random walk scores. The formulation resuts in an optimization problem for which we derive an efficient estimation procedure.

Practically this method outperforms state of the art unsupervised approaches as well as supervised approaches based on complex network feature extraction. An additional benifit of our approach is that no comples network feature extraction or domin expertise are necessary as our algorithm nicely combines the node attribute and network structure information..

Further Related work:
Network inference problem, where no knowledge of network is given
Preferential Attachment, Forest fire model and models based on random walks

Unsupervised methods such as Adamic adar measure of nmode similarity performed best.

link prediction in supervised machine learning setting was mainly studied byt the relational learning community..

random walks on graphs have been considered for computing node proximities in large graphs.. they are also used to rank nodes in graphs..


Supervised Random Walks: Algorithm description

We are given a graph and a node s for which we would like to predict/recommend new link. The idea is that s has already creaed some links and we would like to predct which links it will create next.

for a node s we are given a set of positive and negative training nodes and our algorithm then learns how to distinguish them.. This can be used for link prediction, link recommendation and link anamoly detection.. This can be generalized to a setting where prediction and recommendation is not being made for only a single node s but for a group of nodes..

We can consider it as an classification task.. but the first issue with this approach is of class imbalance.. s will create edges to a small fraction of total nodes and learning is particularly hard to do with very high class imbalance..
It is hard to come up with features that describe the network structure and patterns of connectivity between the pair of nodes under consideration.
Even in a simple undirected graph with no node/edge attributes, there are countless ways to describe proximity of two nodes.. 
we might consider one feature as number of common nodes between two nodes of theedge
we might adjust the proximity scores based on the degrees of two nodes..

The second general approach is to the link prediction prblem is to think about it as a task to rank the nodes of the network.. The idea is to design an algorithm that will assign higher scores to nodes which s created links to than to those s did not create links.. Page rank, personalized page rank and random walks with restarts.. On simple idea is to start random walk at node s and compute prximity of each other node to node s.. We set up a random jump vector so that the walk only jumps back to s and thus restarts the walk.. The stationary distributioin of such random walk assigns each node a score which gives us ranking of how close to the node s are other node s are other nodes in the network.. 

We combine these two appraches into a single framework that will at the sametime consider rich node and edge features as well as the network structure..

The main idea is to use random walk with restarts we compute node proximities on graphs based on network structure. however we then use node and edge attribute data to bias the random walk so that it will more often visit nodes to which s creates edges in future


We are given a source node s, set of destination nodes d1....dk D, and s will create edges in the near future.. Now, we aim to bias the network so that it will visit nodes d more often than other nodes in the network.. one way to bias the random walk is to assign each edge a transition probability.. Traditional page rank assumes that transition perobabiliities to be same, we learn how to assign each edge a transition probability.

We aim mto learn a model(a function) that will assign the transition probability for each edge (u,v) based on the features of nodes u and v as well as features of the edge u,v.. The question is how to directly and in a principled way estimate the parameters of such random walk biasing function

Problem Formulation:

We are given a directed graph G(V,E), a node s and a set of candidates to which s could create an edge. We label nodes to which s could create edge as positive and the rest as negative.. Positve nodes are called Destination nodes and negative nodes are called no-link nodes. We label candidate nodes as with a set C= D union L. Later we generalize to multiple instances of s,L and D. Each node and each edge in G is further described with a set of features. Every edge uv has a feature vector Wuv(psi uv).. foor edge uv we compute strength auv=f(Wuv). f is parameterized by w, takes edge feature vector as input and return strength of the edge..

To predict new edges of node s, first edge strengths of all edges are calculated using fw.. then a random walk with restarts is run from s. The stationary distribution p of random walk assigns each node u, a probability pu.. Nodes are ordered by pu and top ranked nodes are then predicted as destinations of future links of s

The optimimzation problem
